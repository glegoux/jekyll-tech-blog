<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Software Engineering Blog - Gilles Legoux (glegoux)</title>
    <description>Personal blog about software engineering</description>
    <link>https://glegoux.com/</link>
    <atom:link href="https://glegoux.com/rss.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 30 May 2024 06:10:11 +0000</pubDate>
    <lastBuildDate>Thu, 30 May 2024 06:10:11 +0000</lastBuildDate>
    <generator>Jekyll v4.3.2</generator>
    
      <item>
        <title>Top Five Ways to Beat Blue Monday</title>
        <description>&lt;p&gt;Knowing that the year‚Äôs most depressing day is soon can be upsetting. No recurrent day will see everyone feeling depressed. However, periodic factors can contribute to defining the social climate of a society, where statistically, a significant proportion of the population suffers from depression compared to other moments.&lt;/p&gt;

&lt;p&gt;Let‚Äôs understand the Blue Monday effect and how to go over it:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;üìú History&lt;/li&gt;
  &lt;li&gt;üßÆ Formulae&lt;/li&gt;
  &lt;li&gt;üìä Analysis&lt;/li&gt;
  &lt;li&gt;ü™Ñ Tips&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;-history&quot;&gt;üìú History&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Blue_Monday_%28date%29&quot;&gt;Blue Monday&lt;/a&gt;  is a day recognized as the most depressing day of the year, mainly because of the return to work and routine after a weekend and the end of the festivities of the previous year. It is the third Monday of January.&lt;/p&gt;

&lt;p&gt;It was initially created by psychologist Dr. Cliff Arnall in 2005 when he developed the concept as part of a marketing campaign for the now-defunct British company  &lt;a href=&quot;https://en.wikipedia.org/wiki/Sky_Travel&quot;&gt;Sky Travel&lt;/a&gt;. It‚Äôs a fantastic example of how an advertising campaign can become embedded in cultural traditions.&lt;/p&gt;

&lt;h1 id=&quot;-formulae&quot;&gt;üßÆ Formulae&lt;/h1&gt;

&lt;p&gt;Dr. Cliff Arnall suggested a function that models how depressing each day of the year is. By finding the date on which a mathematical formula based on economic, psychological, and climatological factors, then validated by his observations, takes its maximum value on Blue Monday:&lt;/p&gt;

&lt;figure title=&quot;Depression formula ‚Äî not proven scientifically ü§ì&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:223/1*g_U1U3hTBB28XbBAaIiVVg.png&quot; title=&quot;Depression formula ‚Äî not proven scientifically ü§ì&quot; alt=&quot;Depression formula ‚Äî not proven scientifically ü§ì&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    Depression formula ‚Äî not proven scientifically ü§ì
    
      [&lt;a href=&quot;https://en.wikipedia.org/wiki/Blue_Monday_(date)&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;source&lt;/a&gt;]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Where the parameters are the weather (W), the debt (D), the monthly salary (d), the time since Christmas (T), the time since failing our New Year‚Äôs resolutions (Q), low motivational levels (M), and the feeling of the need to take action (Na).&lt;/p&gt;

&lt;p&gt;Later, Dr. Cliff Arnall created the ‚ÄúYellow Day‚Äù, a celebration of the happiest day of the year to counterbalance the saddest day. This time, he was in cahoots with an ice cream manufacturer,  &lt;a href=&quot;https://en.wikipedia.org/wiki/Wall%27s_(ice_cream)&quot;&gt;Wall‚Äôs Ice Cream&lt;/a&gt;, where the period around the 20th of June would be a perfectly happy day thanks to the pleasant temperature, more daylight hours, and holiday perspectives. On a similar approach, the formula is:&lt;/p&gt;

&lt;figure title=&quot;Happiness formula ‚Äî not proven scientifically ü§ì&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:214/1*LfeLEl_pl-iB8PSR5kDf5w.png&quot; title=&quot;Happiness formula ‚Äî not proven scientifically ü§ì&quot; alt=&quot;Happiness formula ‚Äî not proven scientifically ü§ì&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    Happiness formula ‚Äî not proven scientifically ü§ì
    
      [&lt;a href=&quot;https://web.archive.org/web/20110120064745/http://www.ctv.ca/CTVNews/TopStories/20060623/happiest_day_060623&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;source&lt;/a&gt;]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Where the parameters are the outdoor activities (O) in full connection with nature (N) and also the social interactions (I), the childhood and other positive memories  (S), multiplied by the temperature (T), and divided holiday excitement (P).&lt;/p&gt;

&lt;p&gt;Several versions of these mathematical formulae exist. Each one gives periodic dates because they are founded on pseudo-periodic coupled parameters. However, the scientific community considers them as baseless pseudoscience. And they are right. In addition, the mental health of a population can be influenced by many unpredictable phenomena like an economic crisis, an epidemic, or a natural catastrophe. Even if a mathematical formula and/or these annual periodicities were proven, they would be disturbed by it. But time slices exist where the mental health of a whole population is affected. It isn‚Äôt easy to quantify. Only trends can be observed.&lt;/p&gt;

&lt;h1 id=&quot;-read-more&quot;&gt;üëÄ Read more&lt;/h1&gt;

&lt;p&gt;Read the rest of the article ‚Ä¶&lt;/p&gt;

&lt;div style=&quot;text-align: center;margin-bottom: 1em;&quot;&gt;
  &lt;a href=&quot;https://medium.com/@glegoux/top-five-ways-to-beat-blue-monday-0f0de0950827&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; title=&quot;Read more&quot;&gt;
    &lt;button class=&quot;btn btn-dark&quot;&gt;
      &lt;b class=&quot;black&quot;&gt;Read more&lt;/b&gt;
    &lt;/button&gt;
  &lt;/a&gt;
&lt;/div&gt;

</description>
        <pubDate>Wed, 10 Jan 2024 00:00:00 +0000</pubDate>
        <link>https://glegoux.com/blog/articles/2024/01/10/top-five-ways-to-beat-blue-monday.html</link>
        <guid isPermaLink="true">https://glegoux.com/blog/articles/2024/01/10/top-five-ways-to-beat-blue-monday.html</guid>
        
        
        <category>News</category>
        
      </item>
    
      <item>
        <title>Ubuntu: apt-key is deprecated</title>
        <description>&lt;p&gt;&lt;code class=&quot;language-text highlighter-rouge&quot;&gt;apt-key&lt;/code&gt; is deprecated from Ubuntu 22.04 LTS (Jammy Jellyfish) for security flaws: don‚Äôt use it anymore whatever your Linux environment.
Instead of using it, consider the command gpg now. Then move your public keys relative to your APT package manager to a 
new location with the binary format OpenPGP, and specify the option Signed-By (signed-by) for all your used package repositories.&lt;/p&gt;

&lt;p&gt;Let‚Äôs follow this plan together to properly use your secure package management and see if you are not infected by these security flaws:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;üîíUnderstand the security flaws&lt;/li&gt;
  &lt;li&gt;üí° Explore its workstation environment for  &lt;code class=&quot;language-text highlighter-rouge&quot;&gt;apt&lt;/code&gt;  and  &lt;code class=&quot;language-text highlighter-rouge&quot;&gt;apt-key&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;üî® Use directly the  &lt;code class=&quot;language-text highlighter-rouge&quot;&gt;gpg&lt;/code&gt;  command to manage your new keys&lt;/li&gt;
  &lt;li&gt;‚û°Ô∏è Migrate your current trusted public security keys to the correct format and location&lt;/li&gt;
  &lt;li&gt;‚úÖ Check the migration and stop the use&lt;code class=&quot;language-text highlighter-rouge&quot;&gt;apt-key&lt;/code&gt;,  &lt;code class=&quot;language-text highlighter-rouge&quot;&gt;/etc/apt/trusted.gpg&lt;/code&gt;,  &lt;code class=&quot;language-text highlighter-rouge&quot;&gt;/etc/apt/trusted.gpg.d/&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;‚ùîQuestions&lt;/li&gt;
  &lt;li&gt;üöÄ Go further&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;-understand-the-security-flaws&quot;&gt;üîí Understand the security flaws&lt;/h1&gt;

&lt;p&gt;&lt;code class=&quot;language-text highlighter-rouge&quot;&gt;apt-key&lt;/code&gt;  is a sub-command of  &lt;code class=&quot;language-text highlighter-rouge&quot;&gt;apt&lt;/code&gt;  to secure the management packages with asymmetric  security keys. As you know, package management is a sensible area for security; it is an access door for an attacker to install malicious packages. That‚Äôs why when a package is installed, cryptography is used to validate that the installed package is really the one wishes (see  &lt;a href=&quot;https://wiki.debian.org/SecureApt&quot;&gt;Debian Wiki: SecureApt&lt;/a&gt;).&lt;/p&gt;

&lt;figure title=&quot;Security risks in package management&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:700/1*xnkb2pC2ouw_pA97-n8Mjg.png&quot; title=&quot;Security risks in package management&quot; alt=&quot;Security risks in package management&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    Security risks in package management
    
      [built by author]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Here are the milestones of the lifecycle of a package until be installed:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The package is produced on a build machine;&lt;/li&gt;
  &lt;li&gt;The package is signed on the build machine with a private key;&lt;/li&gt;
  &lt;li&gt;The signed package is uploaded to a repository (download mirror);&lt;/li&gt;
  &lt;li&gt;The client system downloads the package (with its package dependencies before if needed) thanks to the metadata and the usage of its package manager from an authorized repository (or from cache);&lt;/li&gt;
  &lt;li&gt;The signature of the package is verified (with its package dependencies before if needed) with the associated public key;&lt;/li&gt;
  &lt;li&gt;If the signature is valid, the package is installed.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The developers of Debian and Ubuntu realized that the apt-key command has had flaws for a long time (see  &lt;a href=&quot;https://security-tracker.debian.org/tracker/source-package/apt&quot;&gt;Security tracker: package apt&lt;/a&gt;  and particularly  &lt;a href=&quot;https://security-tracker.debian.org/tracker/CVE-2011-3374&quot;&gt;CVE-2011‚Äì3374&lt;/a&gt;). While  &lt;code class=&quot;language-text highlighter-rouge&quot;&gt;apt-key&lt;/code&gt;  was not guaranteed to work people continue to use it, that‚Äôs why now this command line has been marked as deprecated (see  &lt;a href=&quot;https://salsa.debian.org/apt-team/apt/-/commit/ee284d5917d09649b68ff1632d44e892f290c52f&quot;&gt;Fully deprecate apt-key, schedule removal for Q2/2022 (ee284d59) ¬∑ Commits ¬∑ APT Developers / apt ¬∑ GitLab&lt;/a&gt;) and will be deleted. Support for the function ends with Debian 11 (Bullseye) and Ubuntu 22.04 (Jammy Jellyfish).&lt;/p&gt;

&lt;p&gt;The problem is to move all tech ecosystems because numerous documentations or blog posts are not up-to-date on this aspect, even the tech giant like  &lt;a href=&quot;https://www.google.com/linuxrepositories/&quot;&gt;Google: Linux Software Repositories&lt;/a&gt;  where the usage of  &lt;code class=&quot;language-text highlighter-rouge&quot;&gt;apt-key&lt;/code&gt;  is still referenced in July 2023.&lt;/p&gt;

&lt;figure title=&quot;The home page of the Google Linux Software Repositories is not up-to-date with the usage of apt-key&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:700/1*uOECpGoz2jU0l2rwQ1t1fw.png&quot; title=&quot;The home page of the Google Linux Software Repositories is not up-to-date with the usage of apt-key&quot; alt=&quot;The home page of the Google Linux Software Repositories is not up-to-date with the usage of apt-key&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    The home page of the Google Linux Software Repositories is not up-to-date with the usage of apt-key
    
      [&lt;a href=&quot;https://www.google.com/linuxrepositories&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;source&lt;/a&gt;]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Let‚Äôs understand an attack scenario among several ones possible. Even if by default, APT checks the validity of the signature of each package to install, and if it is invalid, a warning message is printed and the package is not installed. It is not sufficient because APT needs also to know which trusted public GPG key belongs to which package repository.&lt;/p&gt;

&lt;h1 id=&quot;-read-more&quot;&gt;üëÄ Read more&lt;/h1&gt;

&lt;p&gt;Read the rest of the article ‚Ä¶&lt;/p&gt;

&lt;div style=&quot;text-align: center;margin-bottom: 1em;&quot;&gt;
  &lt;a href=&quot;https://medium.com/@glegoux/ubuntu-22-04-jammy-jellyfish-apt-key-is-deprecated-2dbbee8aec84&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; title=&quot;Read more&quot;&gt;
    &lt;button class=&quot;btn btn-dark&quot;&gt;
      &lt;b class=&quot;black&quot;&gt;Read more&lt;/b&gt;
    &lt;/button&gt;
  &lt;/a&gt;
&lt;/div&gt;

</description>
        <pubDate>Sat, 29 Jul 2023 00:00:00 +0000</pubDate>
        <link>https://glegoux.com/blog/articles/2023/07/29/ubuntu-apt-key-is-deprecated.html</link>
        <guid isPermaLink="true">https://glegoux.com/blog/articles/2023/07/29/ubuntu-apt-key-is-deprecated.html</guid>
        
        
        <category>Security</category>
        
      </item>
    
      <item>
        <title>History of the Generative AI</title>
        <description>&lt;p&gt;&lt;strong&gt;Generative AI&lt;/strong&gt;  is the state of the art of machine learning and has excelled recently with the apparition of  &lt;strong&gt;AI ChatBots with high performance&lt;/strong&gt;.&lt;/p&gt;

&lt;figure title=&quot;Generative AI for all types of content&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:700/1*UenOkL0Tn-XuP-hOho9b3Q.png&quot; title=&quot;Generative AI for all types of content&quot; alt=&quot;Generative AI for all types of content&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    Generative AI for all types of content
    
      [built by author]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Let‚Äôs discover its history, from simple textual machine learning models specialized to  &lt;strong&gt;universal&lt;/strong&gt;  &lt;strong&gt;large language models&lt;/strong&gt; at a vast scale:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;üí¨ AI ChatBots&lt;/li&gt;
  &lt;li&gt;üî• From NLP to Multimodal GAI ChatBots based on LLM&lt;/li&gt;
  &lt;li&gt;üß™LLMs Timeline: Closed-source vs. Open-source&lt;/li&gt;
  &lt;li&gt;üéØ From Specialized Model to Generalized ML Model&lt;/li&gt;
  &lt;li&gt;üìà Scaling Laws &amp;amp; Performance&lt;/li&gt;
  &lt;li&gt;üèÅ Technologic and Economic Race&lt;/li&gt;
  &lt;li&gt;üöÄ Go Further with Limited &amp;amp; Augmented LLMs&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;-ai-chatbots&quot;&gt;üí¨ AI ChatBots&lt;/h1&gt;

&lt;p&gt;Building generalist  &lt;strong&gt;AI chatbots&lt;/strong&gt;  is the most complex challenge for a technology that simulates human intelligence. It is the  &lt;strong&gt;base of the artificial human assistant&lt;/strong&gt;. They are experiencing dazzling success with the  &lt;strong&gt;release of ChatGPT&lt;/strong&gt;, a new step that has been overcome after Google Home and Alexa by AWS. The technical component behind these products has disrupted and improved the ecosystem considerably,  &lt;strong&gt;although not perfect yet&lt;/strong&gt;  (perhaps it will never be).&lt;/p&gt;

&lt;p&gt;The interest in chatBots followed the one for deep learning from 2010. Before, it was reserved for a restrained audience. Still, it exploded in  &lt;strong&gt;November 2022&lt;/strong&gt;  with the release of  &lt;strong&gt;chatGPT&lt;/strong&gt;  open to the general public with a ramp-up of  &lt;strong&gt;100M Monthly Active Users (MAUs) after two months&lt;/strong&gt;, a  worldwide record (4.5x faster than TikTok) and  &lt;strong&gt;1.6B MAUs now&lt;/strong&gt;. At the same time, machine learning and deep learning trends have continued growing in the background for ten years.&lt;/p&gt;

&lt;figure title=&quot;Google Trends from 2010&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:961/1*imwYfo_SLbjeVzeZ420QhQ.png&quot; title=&quot;Google Trends from 2010&quot; alt=&quot;Google Trends from 2010&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    Google Trends from 2010
    
      [&lt;a href=&quot;https://trends.google.com/trends/explore?date=2010-01-01%202023-04-01&amp;amp;geo=FR&amp;amp;q=Machine%20Learning,Deep%20Learning,Chatbot&amp;amp;hl=en&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;source&lt;/a&gt;]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure title=&quot;Similar web for chat.openai.com&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:853/1*bdBhXytZGBsTrI3t-zxd4A.png&quot; title=&quot;Similar web for chat.openai.com&quot; alt=&quot;Similar web for chat.openai.com&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    Similar web for chat.openai.com
    
      [&lt;a href=&quot;https://www.similarweb.com/website/chat.openai.com/#ranking&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;source&lt;/a&gt;]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;To have an order of magnitude, the human brain has, on average, 100 billion neurons and 100 trillion synapses. The estimated resources used for  &lt;strong&gt;chatGPT+&lt;/strong&gt;  (paying version of chatGPT) use deep learning models based on GPT-4 with an estimated model size close to these values (digits kept private by OpenAI). But a  &lt;strong&gt;human neuron/synapse&lt;/strong&gt;  is much more powerful than a  &lt;strong&gt;deep learning neuron/synapse.&lt;/strong&gt; The gap is still important, above on reasoning tasks on unknown problems requiring many resources.&lt;/p&gt;

&lt;figure title=&quot;Human brain vs. Deep learning&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:382/1*Ty6-E7apO67lSr02i-6kvQ.png&quot; title=&quot;Human brain vs. Deep learning&quot; alt=&quot;Human brain vs. Deep learning&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    Human brain vs. Deep learning
    
      [adapted from &lt;a href=&quot;https://www.researchgate.net/figure/Visual-comparison-between-human-nerve-cell-and-neural-network-architecture14_fig3_360640306&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;source&lt;/a&gt;]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h1 id=&quot;from-nlp-to-multimodal-gai-chatbots-based-on-llm&quot;&gt;üî•From NLP to Multimodal GAI ChatBots based on LLM&lt;/h1&gt;

&lt;p&gt;Thanks to  &lt;strong&gt;Large Language Models (LLMs)&lt;/strong&gt;  working with Generative AI, chatBots continue getting closer to the objective of simulating  human intelligence&lt;strong&gt;.&lt;/strong&gt;  The  &lt;strong&gt;NLP AI models&lt;/strong&gt;  have progressively migrated from simple parsing to c&lt;strong&gt;omplex processing on the language structure&lt;/strong&gt;, from shallow learning to  &lt;strong&gt;deep learning&lt;/strong&gt;, from a single-language vocabulary of words to a  &lt;strong&gt;vocabulary of tokens with multi-language embeddings&lt;/strong&gt;, from an RNN (LSTM) to the  &lt;strong&gt;Transformer with multi-head attention layers&lt;/strong&gt;  approach.&lt;/p&gt;

&lt;figure title=&quot;NLP timeline with the Deep Learning&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:700/1*4N5CPyYSVFzfEapqGM5gug.png&quot; title=&quot;NLP timeline with the Deep Learning&quot; alt=&quot;NLP timeline with the Deep Learning&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    NLP timeline with the Deep Learning
    
      [&lt;a href=&quot;https://arxiv.org/pdf/2202.05924.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;source&lt;/a&gt;]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Finally, by mixing other types of data (like images, audio, ‚Ä¶), NLP models became  &lt;strong&gt;multi-modal generative models&lt;/strong&gt; where varied instructions (in input) give varied results (in output).&lt;/p&gt;

&lt;h1 id=&quot;-read-more&quot;&gt;üëÄ Read more&lt;/h1&gt;

&lt;p&gt;Read the rest of the article ‚Ä¶&lt;/p&gt;

&lt;div style=&quot;text-align: center;margin-bottom: 1em;&quot;&gt;
  &lt;a href=&quot;https://medium.com/@glegoux/history-of-the-generative-ai-aa1aa7c63f3c&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; title=&quot;Read more&quot;&gt;
    &lt;button class=&quot;btn btn-dark&quot;&gt;
      &lt;b class=&quot;black&quot;&gt;Read more&lt;/b&gt;
    &lt;/button&gt;
  &lt;/a&gt;
&lt;/div&gt;

</description>
        <pubDate>Sun, 16 Apr 2023 00:00:00 +0000</pubDate>
        <link>https://glegoux.com/blog/articles/2023/04/16/history-of-the-generative-ai.html</link>
        <guid isPermaLink="true">https://glegoux.com/blog/articles/2023/04/16/history-of-the-generative-ai.html</guid>
        
        
        <category>Machine Learning</category>
        
      </item>
    
      <item>
        <title>From Hadoop to the modern data stack</title>
        <description>&lt;h1 id=&quot;hadoop-at-criteo&quot;&gt;Hadoop at Criteo&lt;/h1&gt;

&lt;p&gt;by  &lt;a href=&quot;https://fr.linkedin.com/in/anthony-rabier-345108100&quot;&gt;Anthony Rabier&lt;/a&gt;, Staff Site Reliability Lead Engineer at  &lt;a href=&quot;https://www.criteo.com/&quot;&gt;Criteo&lt;/a&gt;&lt;br /&gt;
and  &lt;a href=&quot;https://fr.linkedin.com/in/williammontaz&quot;&gt;William Montaz&lt;/a&gt;, Senior Staff Site Reliability Engineer at  &lt;a href=&quot;https://www.criteo.com/&quot;&gt;Criteo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Criteo migrated from  &lt;a href=&quot;https://hadoop.apache.org/docs/stable/&quot;&gt;Hadoop&lt;/a&gt;  3 to Hadoop 2, with a lot of patches and in an awesome way by migrating first the runtime to Hadoop 3 for a big progressively without downtime for Hadoop YARN and HDFS without any intervention of the development teams, then by migrating the Hadoop projects for Spark, Flink, and Hadoop Map Reduce. So a vanilla distribution of Hadoop 3 has been created, running with compiled projects in Hadoop 2 and 3 with retro compatibility and tricks developed and merged by Criteo in the core project of Hadoop.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:318/0*Ca5vwq5jxI-Qq2m_&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Migration from Hadoop 2 to Hadoop 3&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/criteo/garmadon&quot;&gt;Garmadon&lt;/a&gt;  is an agent java deployed with all JVM processes running on the Criteo Hadoop cluster to do the metrology jobs for Spark, Flink, and Hadoop Map Reduce ‚Ä¶ You can build generic Grafana dashboards and create data lineage between your dataset and audit all operations on HDFS.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:700/0*OSMVeNYwRB6fQMSC&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Garmadon, Java agent for the Metrology on Hadoop&lt;/p&gt;

&lt;h1 id=&quot;data-processing-at-criteo&quot;&gt;Data processing at Criteo&lt;/h1&gt;

&lt;p&gt;by  &lt;a href=&quot;https://fr.linkedin.com/in/mliroz&quot;&gt;Miguel Liroz&lt;/a&gt;, Senior Staff Site Reliability Lead Engineer at  &lt;a href=&quot;https://www.criteo.com/&quot;&gt;Criteo&lt;/a&gt;&lt;br /&gt;
and  &lt;a href=&quot;https://www.linkedin.com/in/raphaelclaude&quot;&gt;Raphael Claude&lt;/a&gt;, Staff Site Reliability Engineer at  &lt;a href=&quot;https://www.criteo.com/&quot;&gt;Criteo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Datadoc is an internal tool used by Criteo to browse the data catalog and to provide a data catalog on each dataset.&lt;/p&gt;

&lt;figure title=&quot;Datadoc&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:700/1*UD_BHWOi4vMzm_vEQQthvg.png&quot; title=&quot;Datadoc&quot; alt=&quot;Datadoc&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    Datadoc
    
      [built by author]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;a href=&quot;https://medium.com/criteo-engineering/scheduling-data-pipelines-at-criteo-part-1-8b257c6c8e55&quot;&gt;BigDataFlow&lt;/a&gt;  is an internal tool used by Criteo written in Scala to schedule data processing jobs from an extended SQL query.&lt;/p&gt;

&lt;figure title=&quot;BigDataFlow extended SQL&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:700/1*cRzS5MJ4IiErfXQ82Sz5Ug.png&quot; title=&quot;BigDataFlow extended SQL&quot; alt=&quot;BigDataFlow extended SQL&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    BigDataFlow extended SQL
    
      [built by author]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h1 id=&quot;-read-more&quot;&gt;üëÄ Read more&lt;/h1&gt;

&lt;p&gt;Read the rest of the article ‚Ä¶&lt;/p&gt;

&lt;div style=&quot;text-align: center;margin-bottom: 1em;&quot;&gt;
  &lt;a href=&quot;https://medium.com/@glegoux/from-hadoop-to-the-modern-stack-cdb2f10cee31&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; title=&quot;Read more&quot;&gt;
    &lt;button class=&quot;btn btn-dark&quot;&gt;
      &lt;b class=&quot;black&quot;&gt;Read more&lt;/b&gt;
    &lt;/button&gt;
  &lt;/a&gt;
&lt;/div&gt;

</description>
        <pubDate>Wed, 14 Dec 2022 00:00:00 +0000</pubDate>
        <link>https://glegoux.com/blog/articles/2022/12/14/from-hadoop-to-the-modern-data-stack.html</link>
        <guid isPermaLink="true">https://glegoux.com/blog/articles/2022/12/14/from-hadoop-to-the-modern-data-stack.html</guid>
        
        
        <category>Data</category>
        
      </item>
    
      <item>
        <title>How to write a README?</title>
        <description>&lt;p&gt;A README is the best place to start documenting a project. A README is normally a  &lt;strong&gt;single-page document&lt;/strong&gt;  describing your computer project‚Äôs key aspects. This document can be read in a few minutes maximum. It is the open door for a newcomer who wants an overview of the fundamental aspects of the project.&lt;/p&gt;

&lt;p&gt;Having a README for a computer project is a  &lt;strong&gt;common&lt;/strong&gt;  enough &lt;strong&gt;thing&lt;/strong&gt;  for the code repositories. Still, the  &lt;strong&gt;template&lt;/strong&gt;  defining what should contain this README is not standard and often depends on the  &lt;strong&gt;sensibility of the software documentalist&lt;/strong&gt;. Avoiding gaps in content and format allows you to align the shared knowledge of your projects in the best common possible way.&lt;/p&gt;

&lt;p&gt;The rules for writing a README file will be described with a generic template and a pragmatic methodology agnostic to the tech stack and the project type you use.&lt;/p&gt;

&lt;p&gt;First, let‚Äôs begin defining the type of project that you can have.&lt;/p&gt;

&lt;p&gt;A  &lt;strong&gt;project&lt;/strong&gt; is a code repository; it can be composed of either one module (&lt;strong&gt;simple project&lt;/strong&gt;) or several modules (&lt;strong&gt;complex project&lt;/strong&gt;). This project is in an ecosystem composed of dependencies between modules of the same project or other projects. A module can be :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;An  &lt;strong&gt;application&lt;/strong&gt;: It is deployed at runtime with an executable. No other module depends on it except optionally at runtime.&lt;/li&gt;
  &lt;li&gt;A  &lt;strong&gt;library&lt;/strong&gt;: It‚Äôs used by other modules that depend on it for their execution and/or build.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For example, a  &lt;strong&gt;type of project&lt;/strong&gt;  can be a code library in (Python, Scala, or Java ‚Ä¶), an SDK, a web app with a UI and/or an API, a machine learning model, a data processor, a set of scripts, an OPS configuration module or a scheduled job ‚Ä¶&lt;/p&gt;

&lt;p&gt;All projects have not necessarily needed a README respected rigorous template; it can use a degraded version in function efforts that you want to provide. Only  &lt;strong&gt;mature projects&lt;/strong&gt;  where you want a high level of quality need it, that is to say, for a project used by the community in an intensive or critical way.&lt;/p&gt;

&lt;h1 id=&quot;practical-guidelines&quot;&gt;Practical guidelines&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;Here are explained the practical guidelines that a README should respect.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;For a simple project:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The README should be a simple text file called README.&lt;extension&gt;.&lt;/extension&gt;&lt;/li&gt;
  &lt;li&gt;It should be written in coherent syntax (like  &lt;code class=&quot;language-text highlighter-rouge&quot;&gt;Markdown&lt;/code&gt;  or  &lt;code class=&quot;language-text highlighter-rouge&quot;&gt;reStructuredText&lt;/code&gt;).&lt;/li&gt;
  &lt;li&gt;There should be a README at the root of the project.&lt;/li&gt;
  &lt;li&gt;According to the README variant you choose (see sections below), you need to adhere to the variant structure.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For a complex project:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The README at the root must have links to the ones of each submodule, with a sentence to describe the role of each module&lt;/li&gt;
  &lt;li&gt;It should have a README for each module&lt;/li&gt;
  &lt;li&gt;The README of each module should respect the guidelines of a simple project&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;template&quot;&gt;Template&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;Here are the sections that README should contain.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Each  &lt;strong&gt;section&lt;/strong&gt;  can contain  &lt;strong&gt;direct or indirect information&lt;/strong&gt;  with  &lt;strong&gt;links&lt;/strong&gt;  and should contain a  &lt;strong&gt;title section&lt;/strong&gt;  with format H1 (i.e., ‚Äò#‚Äô with markdown). A section can be  &lt;strong&gt;optional&lt;/strong&gt;  and  &lt;strong&gt;required&lt;/strong&gt;  in function of the type of modules.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;[Project Title]&lt;/strong&gt;* [*: required]
    &lt;ul&gt;
      &lt;li&gt;High-level description (with a demo link if applicable)&lt;/li&gt;
      &lt;li&gt;It should indicate if it is a  &lt;code class=&quot;language-text highlighter-rouge&quot;&gt;library&lt;/code&gt;  or an  &lt;code class=&quot;language-text highlighter-rouge&quot;&gt;application  
&lt;/code&gt;- It should indicate who is the owner of this project&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Quick start&lt;/strong&gt;* [*: required]
    &lt;ul&gt;
      &lt;li&gt;How to set up the development environment, get the repository, install tech stack, ‚Ä¶&lt;/li&gt;
      &lt;li&gt;Link to a demo&lt;/li&gt;
      &lt;li&gt;How to run the project&lt;/li&gt;
      &lt;li&gt;How to run the tests&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Usage&lt;/strong&gt;  [optional only if relevant and helpful]
    &lt;ul&gt;
      &lt;li&gt;How to use the project (ex. API description)&lt;/li&gt;
      &lt;li&gt;Links to help resources&lt;/li&gt;
      &lt;li&gt;How to contribute to the project (coding style, code of conduct, ‚Ä¶)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Main structure&lt;/strong&gt;* [*: required]
    &lt;ul&gt;
      &lt;li&gt;Link(s) to other ‚Äúsub-README(s)‚Äù (only if the module has submodules)&lt;/li&gt;
      &lt;li&gt;Links to dependencies&lt;/li&gt;
      &lt;li&gt;Describe the file architecture of the repository&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Architecture&lt;/strong&gt; [optional only if relevant and helpful]
    &lt;ul&gt;
      &lt;li&gt;Explanation of the design with a diagram and a description ‚Ä¶&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Deployment&lt;/strong&gt;**  [**: required only for a deployed application]
    &lt;ul&gt;
      &lt;li&gt;Link to the deployment configuration&lt;/li&gt;
      &lt;li&gt;Link to this history of the deployment with the changelog and the releases&lt;/li&gt;
      &lt;li&gt;Link to the deployed application&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Monitoring&lt;/strong&gt;**  [**: required only for a deployed application]
    &lt;ul&gt;
      &lt;li&gt;Links to monitoring dashboards, ‚Ä¶&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;References&lt;/strong&gt;  [required]
    &lt;ul&gt;
      &lt;li&gt;Links to the documentation about specifications, improvements, or maintenance‚Ä¶&lt;/li&gt;
      &lt;li&gt;Other useful links&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;License&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Link to the license and copyright with the general conditions&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;-read-more&quot;&gt;üëÄ Read more&lt;/h1&gt;

&lt;p&gt;Read the rest of the article ‚Ä¶&lt;/p&gt;

&lt;div style=&quot;text-align: center;margin-bottom: 1em;&quot;&gt;
  &lt;a href=&quot;https://medium.com/@glegoux/how-to-write-a-readme-f8986d407c1e&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; title=&quot;Read more&quot;&gt;
    &lt;button class=&quot;btn btn-dark&quot;&gt;
      &lt;b class=&quot;black&quot;&gt;Read more&lt;/b&gt;
    &lt;/button&gt;
  &lt;/a&gt;
&lt;/div&gt;

</description>
        <pubDate>Sat, 10 Dec 2022 00:00:00 +0000</pubDate>
        <link>https://glegoux.com/blog/articles/2022/12/10/how-to-write-a-readme.html</link>
        <guid isPermaLink="true">https://glegoux.com/blog/articles/2022/12/10/how-to-write-a-readme.html</guid>
        
        
        <category>Documentation</category>
        
      </item>
    
      <item>
        <title>Aerospike: Real-time database for the online ads ecosystem</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://aerospike.com/&quot;&gt;Aerospike&lt;/a&gt;  can replace at the same time 2 cache layers, an in-memory layer, and a persistent memory layer like  &lt;a href=&quot;https://memcached.org/&quot;&gt;Memcached&lt;/a&gt;  and  &lt;a href=&quot;https://www.couchbase.com/&quot;&gt;Couchbase&lt;/a&gt;, respectively, with awesome performance.&lt;/p&gt;

&lt;p&gt;Especially explore the usages of this distributed key-value store for the e-commerce catalogs indispensable in the online ads ecosystem to build ad campaigns, recommend products to the right audience, and display the ads for the publishers.&lt;/p&gt;

&lt;p&gt;As a member of catalog teams at Criteo, I was at the last meetup of  &lt;a href=&quot;https://www.meetup.com/aerospike-paris-scale-warrior-meet-ups/events/289187127/&quot;&gt;Scale Warriors Aerospike&lt;/a&gt;, where the CTO (and founder at Aerospike) was present  &lt;a href=&quot;https://www.linkedin.com/in/drvsrini/&quot;&gt;Srini V. Srinivasan&lt;/a&gt;  to share new and existing features of Aerospike, and where Criteo presented its plan and strategy to migrate to Aerospike.&lt;/p&gt;

&lt;h1 id=&quot;aerospike&quot;&gt;Aerospike&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Aerospike&lt;/strong&gt;  is a key-value NoSQL database with  &lt;a href=&quot;https://en.wikipedia.org/wiki/Flash_memory&quot;&gt;flash memory&lt;/a&gt;  and  &lt;a href=&quot;https://en.wikipedia.org/wiki/In-memory_database&quot;&gt;in-memory&lt;/a&gt;  &lt;a href=&quot;https://github.com/aerospike&quot;&gt;open source&lt;/a&gt;. The high-level ecosystem of Aerospike is deeply integrated with tools of the Big data ecosystem for streaming, batch, and SQL usages with  &lt;a href=&quot;https://www.confluent.io/lp/apache-kafka/&quot;&gt;Kafka&lt;/a&gt;,  &lt;a href=&quot;https://spark.apache.org/&quot;&gt;Spark&lt;/a&gt;, and  &lt;a href=&quot;https://trino.io/&quot;&gt;Trino&lt;/a&gt;  with a  &lt;a href=&quot;https://developer.aerospike.com/client/java&quot;&gt;Java client&lt;/a&gt;:&lt;/p&gt;

&lt;figure title=&quot;The Aerospike Real-time Data Platform&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:700/1*83KoE4CmWbOJFgxFU6paeQ.png&quot; title=&quot;The Aerospike Real-time Data Platform&quot; alt=&quot;The Aerospike Real-time Data Platform&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    The Aerospike Real-time Data Platform
    
      [&lt;a href=&quot;https://aerospike.com/developer/blog/database-queries-json-db-6&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;source&lt;/a&gt;]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Aerospike is a distributed key-value store. You can access the data with a simple API:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Get(key) -&amp;gt; byte[]&lt;br /&gt;
Set(key, byte[], ttl)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The goal is to have small objects from a few bytes to 4 MiB, with low latency, 1 ms on average, and 5 ms at the 99th percentile.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Aerospike is first optimized for the OLTP paradigm because it is a KV Store.&lt;/strong&gt; Still, you can easily do OLAP queries for other usages for more exotic queries to scan the data thanks to the data models layer for Documents, SQL, Graphs, or Time Series.&lt;/p&gt;

&lt;h1 id=&quot;aerospike-clusters-at-criteo&quot;&gt;Aerospike clusters at Criteo&lt;/h1&gt;

&lt;p&gt;A DKVS plays a central role in online ads. With this storage, the infrastructure can answer to the small-time budgets required for each business use case: to bid a request for the auction of RTB (&amp;lt; 100 ms) or to render the ads (&amp;lt; 250 ms).&lt;/p&gt;

&lt;figure title=&quot;Time budget for the online ads&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:700/1*huw1bvBiZIDuDliExf6bOg.png&quot; title=&quot;Time budget for the online ads&quot; alt=&quot;Time budget for the online ads&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    Time budget for the online ads
    
      [&lt;a href=&quot;https://www.meetup.com/aerospike-paris-meet-ups/events/289187127&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;source&lt;/a&gt;]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The tech stack is diversified to respond to the needs of online ads, and a DKVS is insufficient. It is only a part of the ecosystem:&lt;/p&gt;

&lt;figure title=&quot;Data stack at Criteo&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:700/1*2czh312iW3IsFkVU1YfW3w.png&quot; title=&quot;Data stack at Criteo&quot; alt=&quot;Data stack at Criteo&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    Data stack at Criteo
    
      [&lt;a href=&quot;https://www.meetup.com/aerospike-paris-meet-ups/events/289187127&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;source&lt;/a&gt;]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The data stored in the KV stores must be persisted and loaded in memory to access long-term and quick readings.&lt;/p&gt;

&lt;h1 id=&quot;-read-more&quot;&gt;üëÄ Read more&lt;/h1&gt;

&lt;p&gt;Read the rest of the article ‚Ä¶&lt;/p&gt;

&lt;div style=&quot;text-align: center;margin-bottom: 1em;&quot;&gt;
  &lt;a href=&quot;https://medium.com/@glegoux/aerospike-real-time-database-c88066769274&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; title=&quot;Read more&quot;&gt;
    &lt;button class=&quot;btn btn-dark&quot;&gt;
      &lt;b class=&quot;black&quot;&gt;Read more&lt;/b&gt;
    &lt;/button&gt;
  &lt;/a&gt;
&lt;/div&gt;

</description>
        <pubDate>Tue, 29 Nov 2022 00:00:00 +0000</pubDate>
        <link>https://glegoux.com/blog/articles/2022/11/29/aerospike-real-time-database-for-the-online-ads-ecosystem.html</link>
        <guid isPermaLink="true">https://glegoux.com/blog/articles/2022/11/29/aerospike-real-time-database-for-the-online-ads-ecosystem.html</guid>
        
        
        <category>Data</category>
        
      </item>
    
      <item>
        <title>Learning PySpark with Google Colab</title>
        <description>&lt;p&gt;Learning  &lt;a href=&quot;https://spark.apache.org/&quot;&gt;&lt;strong&gt;Apache Spark&lt;/strong&gt;&lt;/a&gt;  with a quick learning curve is challenging. Discover  &lt;strong&gt;distributed computation&lt;/strong&gt;  and  &lt;strong&gt;machine learning&lt;/strong&gt;  with  &lt;a href=&quot;https://www.databricks.com/glossary/pyspark&quot;&gt;PySpark&lt;/a&gt;, with  &lt;strong&gt;several tutorials&lt;/strong&gt;  until building your movie recommendation engine.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Links:&lt;/strong&gt; &lt;a href=&quot;https://github.com/criteo-research/master-iasd/tree/master/module4&quot;&gt;GitHub&lt;/a&gt;  |  &lt;a href=&quot;https://colab.research.google.com/github/criteo-research/master-iasd/blob/master/module4/td1/td1-rdd-questions.ipynb&quot;&gt;Tutorials quick start&lt;/a&gt;  |  &lt;a href=&quot;https://grouplens.org/datasets/movielens/&quot;&gt;Dataset&lt;/a&gt;&lt;/p&gt;

&lt;figure title=&quot;&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:359/1*HZloIx45zZtPrtcEksmeRw.png&quot; title=&quot;&quot; alt=&quot;&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Let‚Äôs discover how to use PySpark on Google Colab with accessible tutorials.&lt;/p&gt;

&lt;p&gt;As a teaching fellow with  &lt;a href=&quot;https://www.linkedin.com/in/david-diebold-51249977/&quot;&gt;David Diebold&lt;/a&gt;  about  &lt;a href=&quot;https://www.lamsade.dauphine.fr/wp/iasd/en/programme/options/systemes-paradigmes-et-langages-pour-les-big-data/&quot;&gt;Systems, paradigms, and algorithms for Big Data&lt;/a&gt;  for the international  &lt;a href=&quot;https://www.lamsade.dauphine.fr/wp/iasd/en/&quot;&gt;Master IASD&lt;/a&gt;  (&lt;a href=&quot;https://www.universite-paris-saclay.fr/en/education/french-higher-education-system&quot;&gt;graduate degree M2&lt;/a&gt;) for the French  &lt;a href=&quot;https://dauphine.psl.eu/&quot;&gt;Dauphine Paris University&lt;/a&gt;  member of the  &lt;a href=&quot;https://psl.eu/en&quot;&gt;PSL University&lt;/a&gt;, I needed to organize sessions of tutorials for the students on the distributed computation with  &lt;a href=&quot;https://spark.apache.org/&quot;&gt;&lt;strong&gt;Apache Spark&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fast, flexible, and developer-friendly&lt;/strong&gt;, this  &lt;strong&gt;data-distributed processing&lt;/strong&gt;  framework has become  &lt;strong&gt;one of the world‚Äôs most significant&lt;/strong&gt;. Before teaching the features provided by Spark, we had to choose  &lt;strong&gt;which language and platform&lt;/strong&gt;  our learners could run the tutorials we prepared. We chose the tech stack:  &lt;strong&gt;PySpark with Google Colab&lt;/strong&gt;.&lt;/p&gt;

&lt;h1 id=&quot;pyspark-vs-spark&quot;&gt;PySpark vs. Spark&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://www.databricks.com/glossary/pyspark&quot;&gt;&lt;strong&gt;PySpark&lt;/strong&gt;&lt;/a&gt;  allows interaction with Spark in  &lt;strong&gt;Python&lt;/strong&gt;. It gives a  &lt;strong&gt;better learning curve&lt;/strong&gt;  than Spark (written originally in Scala). Even though it is less performant for a production world using  &lt;a href=&quot;https://www.py4j.org/&quot;&gt;Py4J&lt;/a&gt;  to interact with the JVM of Spark, it gives  &lt;strong&gt;sufficient performance&lt;/strong&gt;  (sometimes close to Spark with Java/Scala) to experiment with distributed data science and machine learning.&lt;/p&gt;

&lt;figure title=&quot;PySpark is an interaction of Spark with Python&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:571/1*jLK8saUaKj8KuovUgXumUg.png&quot; title=&quot;PySpark is an interaction of Spark with Python&quot; alt=&quot;PySpark is an interaction of Spark with Python&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    PySpark is an interaction of Spark with Python
    
      [built by author]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;PySpark with Python remains largely the  &lt;strong&gt;preferred language&lt;/strong&gt;  for  &lt;strong&gt;Notebooks.&lt;/strong&gt;&lt;/p&gt;

&lt;figure title=&quot;Percent of commands on the Databricks platform in each Spark language &quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:344/1*L8jzF1__70sSDfflDM5CBg.png&quot; title=&quot;Percent of commands on the Databricks platform in each Spark language &quot; alt=&quot;Percent of commands on the Databricks platform in each Spark language &quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    Percent of commands on the Databricks platform in each Spark language 
    
      [&lt;a href=&quot;https://www.databricks.com/blog/2020/06/18/introducing-apache-spark-3-0-now-available-in-databricks-runtime-7-0.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;source&lt;/a&gt;]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The  &lt;strong&gt;support&lt;/strong&gt;  of PySpark is already  &lt;strong&gt;excellent&lt;/strong&gt;  and continues to be improved with the future version of  &lt;a href=&quot;https://www.databricks.com/blog/2020/06/18/introducing-apache-spark-3-0-now-available-in-databricks-runtime-7-0.html&quot;&gt;&lt;strong&gt;Spark 3+&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Python is  &lt;strong&gt;easier to learn&lt;/strong&gt;  than Scala and has a  &lt;strong&gt;mature ecosystem for applied mathematics&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;For these reasons,  &lt;strong&gt;we preferred teaching PySpark over Spark&lt;/strong&gt;. Moving from one to another is easy, only the cost for the learners to become familiar with the Scala/Java ecosystem for advanced use.&lt;/p&gt;

&lt;h1 id=&quot;-read-more&quot;&gt;üëÄ Read more&lt;/h1&gt;

&lt;p&gt;Read the rest of the article ‚Ä¶&lt;/p&gt;

&lt;div style=&quot;text-align: center;margin-bottom: 1em;&quot;&gt;
  &lt;a href=&quot;https://medium.com/@glegoux/apache-spark-pyspark-with-google-colab-for-data-science-63478138a63e&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; title=&quot;Read more&quot;&gt;
    &lt;button class=&quot;btn btn-dark&quot;&gt;
      &lt;b class=&quot;black&quot;&gt;Read more&lt;/b&gt;
    &lt;/button&gt;
  &lt;/a&gt;
&lt;/div&gt;

</description>
        <pubDate>Tue, 15 Nov 2022 00:00:00 +0000</pubDate>
        <link>https://glegoux.com/blog/articles/2022/11/15/learning-pyspark-with-google-colab.html</link>
        <guid isPermaLink="true">https://glegoux.com/blog/articles/2022/11/15/learning-pyspark-with-google-colab.html</guid>
        
        
        <category>Data</category>
        
      </item>
    
      <item>
        <title>The Apache Software Foundation for the open-source</title>
        <description>&lt;p&gt;ASF is one of the larger foundations for open-source projects in the tech world. The official website  &lt;a href=&quot;https://apache.org/&quot;&gt;https://apache.org/&lt;/a&gt;  is exhaustive of useful information.&lt;/p&gt;

&lt;figure title=&quot;Metrics about the Apache Foundation&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:700/1*zIWuiiqmXct1v7HjBxCFUA.png&quot; title=&quot;Metrics about the Apache Foundation&quot; alt=&quot;Metrics about the Apache Foundation&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    Metrics about the Apache Foundation
    
      [&lt;a href=&quot;https://apache.org&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;source&lt;/a&gt;]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h1 id=&quot;apache-organization&quot;&gt;Apache Organization&lt;/h1&gt;

&lt;p&gt;The organization of ASF is complex enough, here are useful like to understand how it works:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.apache.org/foundation/how-it-works.html&quot;&gt;https://www.apache.org/foundation/how-it-works.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://apache.org/foundation/&quot;&gt;https://apache.org/foundation/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.apache.org/foundation/governance/orgchart&quot;&gt;https://www.apache.org/foundation/governance/orgchart&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;apache-community&quot;&gt;Apache community&lt;/h1&gt;

&lt;p&gt;See  &lt;a href=&quot;https://community.apache.org/&quot;&gt;https://community.apache.org/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;apache-way-core-values&quot;&gt;Apache Way: Core values&lt;/h1&gt;

&lt;p&gt;It is a set of methodologies and values designed to enable disparate communities of volunteers to work collaboratively over time.&lt;/p&gt;

&lt;p&gt;See  &lt;a href=&quot;https://www.apache.org/theapacheway/&quot;&gt;https://www.apache.org/theapacheway/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;apache-news&quot;&gt;Apache News&lt;/h1&gt;

&lt;p&gt;ApacheCon is a conference that is a must for anyone who works deeply with Apache-based software programs.&lt;/p&gt;

&lt;figure title=&quot;ApacheCon&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:206/1*bbdfE_HQ-S98x0vUV5Dgnw.png&quot; title=&quot;ApacheCon&quot; alt=&quot;ApacheCon&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    ApacheCon
    
      [&lt;a href=&quot;http://www.apachecon.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;source&lt;/a&gt;]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;See the old conferences:  &lt;a href=&quot;https://archive.apachecon.com/&quot;&gt;https://archive.apachecon.com/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;See all the Apache events:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://events.apache.org/event/&quot;&gt;https://events.apache.org/event/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Apache Blog posts:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://news.apache.org/&quot;&gt;https://news.apache.org/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blogs.apache.org/&quot;&gt;https://blogs.apache.org/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Apache Reports:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.apache.org/foundation/reports.html&quot;&gt;https://www.apache.org/foundation/reports.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;apache-sponsors&quot;&gt;Apache sponsors&lt;/h1&gt;

&lt;p&gt;See  &lt;a href=&quot;https://apache.org/foundation/thanks&quot;&gt;https://apache.org/foundation/thanks&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;-read-more&quot;&gt;üëÄ Read more&lt;/h1&gt;

&lt;p&gt;Read the rest of the article ‚Ä¶&lt;/p&gt;

&lt;div style=&quot;text-align: center;margin-bottom: 1em;&quot;&gt;
  &lt;a href=&quot;https://medium.com/@glegoux/top-five-ways-to-beat-blue-monday-0f0de0950827&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; title=&quot;Read more&quot;&gt;
    &lt;button class=&quot;btn btn-dark&quot;&gt;
      &lt;b class=&quot;black&quot;&gt;Read more&lt;/b&gt;
    &lt;/button&gt;
  &lt;/a&gt;
&lt;/div&gt;

</description>
        <pubDate>Sun, 13 Nov 2022 00:00:00 +0000</pubDate>
        <link>https://glegoux.com/blog/articles/2022/11/13/the-apache-software-foundation-for-the-open-source.html</link>
        <guid isPermaLink="true">https://glegoux.com/blog/articles/2022/11/13/the-apache-software-foundation-for-the-open-source.html</guid>
        
        
        <category>News</category>
        
      </item>
    
      <item>
        <title>Apache Spark: Ecosystem overview with Apache Hadoop YARN and HDFS</title>
        <description>&lt;p&gt;Apache Spark: ecosystem overview with Apache Hadoop YARN and HDFS&lt;a href=&quot;https://spark.apache.org/&quot;&gt;Apache Spark‚Ñ¢&lt;/a&gt;  is a multi-language engine for executing data engineerinApache Spark: ecosystem overview with Apache Hadoop YARN and HDFSg, data science, and machine learning on single-node machines or clusters. It is largely used in the industry for distributed computation of data at scale.&lt;/p&gt;

&lt;p&gt;This project is  &lt;a href=&quot;https://github.com/apache/spark&quot;&gt;open-source&lt;/a&gt;  under the  &lt;a href=&quot;https://apache.org/&quot;&gt;Apache software foundation,&lt;/a&gt;  created by the founders of the company  &lt;a href=&quot;https://www.databricks.com/&quot;&gt;Databricks&lt;/a&gt;  that provides cluster and support for Spark.&lt;/p&gt;

&lt;p&gt;Let deep dive on the architecture of  &lt;strong&gt;Apache Spark on YARN&lt;/strong&gt; in a distributed ecosystem of containers and  &lt;strong&gt;Java VMs&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;This architecture need to address the  &lt;strong&gt;computation&lt;/strong&gt;  and the  &lt;strong&gt;storage&lt;/strong&gt;  at  &lt;strong&gt;high scale&lt;/strong&gt;  to manipulate big volume of data with an efficient processing.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Table of contents&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Spark ecosystem&lt;/li&gt;
  &lt;li&gt;Spark architecture through Hadoop&lt;/li&gt;
  &lt;li&gt;Spark engine for computation and storage&lt;/li&gt;
  &lt;li&gt;Go with Spark in production&lt;/li&gt;
  &lt;li&gt;Example of Spark application at Scale&lt;/li&gt;
  &lt;li&gt;Go further&lt;/li&gt;
  &lt;li&gt;What‚Äôs next&lt;/li&gt;
  &lt;li&gt;Thanks to&lt;/li&gt;
  &lt;li&gt;Glossary&lt;/li&gt;
  &lt;li&gt;References&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let‚Äôs start with the basics, you can jump straight to the sections that interest you, otherwise see vertically how this whole ecosystem works.&lt;/p&gt;

&lt;h1 id=&quot;spark-ecosystem&quot;&gt;Spark ecosystem&lt;/h1&gt;

&lt;h2 id=&quot;data-pipelines&quot;&gt;Data pipelines&lt;/h2&gt;

&lt;p&gt;Spark allows building data pipeline in  &lt;strong&gt;batch mode&lt;/strong&gt; and the  &lt;strong&gt;streaming mode&lt;/strong&gt;.&lt;/p&gt;

&lt;figure title=&quot;Lambda architecture with Spark&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:408/0*zqTHvZ2Uckv_Hjz3.png&quot; title=&quot;Lambda architecture with Spark&quot; alt=&quot;Lambda architecture with Spark&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    Lambda architecture with Spark
    
      [&lt;a href=&quot;true&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;source&lt;/a&gt;]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Here, you see a  &lt;strong&gt;lambda architecture&lt;/strong&gt;, but to associate online and offline processing, you can have a  &lt;strong&gt;kappa&lt;/strong&gt;  or  &lt;strong&gt;zeta&lt;/strong&gt;  &lt;strong&gt;architecture&lt;/strong&gt;  on your data pipeline. You will see it in another article.&lt;/p&gt;

&lt;figure title=&quot;Spark vs Spark Streaming&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:394/1*4QrgYLPJto1TBvMcs45iqg.png&quot; title=&quot;Spark vs Spark Streaming&quot; alt=&quot;Spark vs Spark Streaming&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    Spark vs Spark Streaming
    
      [built by author]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The streaming mode of Spark is more micro-batch approach. Other framework like  &lt;a href=&quot;https://kafka.apache.org/documentation/streams/&quot;&gt;Kafka Streaming&lt;/a&gt;,  &lt;a href=&quot;https://faust-streaming.github.io/faust/&quot;&gt;Faust Streaming&lt;/a&gt;  or  &lt;a href=&quot;https://flink.apache.org/&quot;&gt;Apache Flink&lt;/a&gt;  are more used to process data streams. Spark is forceful to process data batch overall.&lt;/p&gt;

&lt;h2 id=&quot;apis&quot;&gt;APIs&lt;/h2&gt;

&lt;p&gt;Mainly, Spark can run with several APIs, one for each following programming language  &lt;a href=&quot;https://spark.apache.org/docs/latest/api/scala/org/apache/spark/index.html&quot;&gt;Scala&lt;/a&gt;/&lt;a href=&quot;https://spark.apache.org/docs/latest/api/java/&quot;&gt;Java&lt;/a&gt;,  &lt;a href=&quot;https://spark.apache.org/docs/latest/api/python/&quot;&gt;Python&lt;/a&gt;  and  &lt;a href=&quot;https://spark.apache.org/docs/latest/api/R/&quot;&gt;R&lt;/a&gt;, respectively with  &lt;strong&gt;Spark&lt;/strong&gt;,  &lt;strong&gt;PySpark&lt;/strong&gt;  and  &lt;strong&gt;SparkR&lt;/strong&gt;.&lt;/p&gt;

&lt;figure title=&quot;Different types of Spark engines&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:700/1*zXXVD_S-pBs8mWBi3OcR7w.png&quot; title=&quot;Different types of Spark engines&quot; alt=&quot;Different types of Spark engines&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    Different types of Spark engines
    
      [built by author]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In practice, Spark and PySpark are more used than SparkR. For the experimentation, PySpark is more helpful, and for the performances Spark is better.&lt;/p&gt;

&lt;h2 id=&quot;connectors&quot;&gt;Connectors&lt;/h2&gt;

&lt;p&gt;Spark has many  &lt;strong&gt;connectors&lt;/strong&gt;  to write  &lt;strong&gt;to different types of storage&lt;/strong&gt;.&lt;/p&gt;

&lt;figure title=&quot;Apache Spark‚Äôs ecosystem of connectors&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:684/0*uQtzEnoXUORb2dgi&quot; title=&quot;Apache Spark‚Äôs ecosystem of connectors&quot; alt=&quot;Apache Spark‚Äôs ecosystem of connectors&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    Apache Spark‚Äôs ecosystem of connectors
    
      [&lt;a href=&quot;https://pages.databricks.com/rs/094-YMS-629/images/LearningSpark2.0.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;source&lt;/a&gt;]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Here, we are going to speak a bit more about the connection with Apache Hadoop HDFS.&lt;/p&gt;

&lt;h2 id=&quot;spark-sql&quot;&gt;Spark SQL&lt;/h2&gt;

&lt;p&gt;In addition, you can also run Spark with  &lt;a href=&quot;https://spark.apache.org/docs/latest/api/sql/&quot;&gt;SQL&lt;/a&gt;. With a SQL request, you can also access to heterogeneous data then combine them in memory:&lt;/p&gt;

&lt;figure title=&quot;Spark SQL overview&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:720/format:webp/0*Ts-DH76DiRFZh4p1.png&quot; title=&quot;Spark SQL overview&quot; alt=&quot;Spark SQL overview&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    Spark SQL overview
    
      [&lt;a href=&quot;http://www.gatorsmile.io/sparksqloverview/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;source&lt;/a&gt;]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The  &lt;a href=&quot;https://www.linkedin.com/pulse/catalyst-tungsten-apache-sparks-speeding-engine-deepak-rajak/&quot;&gt;Catalyst &amp;amp; Tungsten&lt;/a&gt; engines allows optimizing the execution plan of the query:&lt;/p&gt;

&lt;figure title=&quot;Catalyst&quot; class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://miro.medium.com/v2/resize:fit:700/0*CRcfOe8vbDWNGJhV.png&quot; title=&quot;Catalyst&quot; alt=&quot;Catalyst&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    Catalyst
    
      [&lt;a href=&quot;https://www.databricks.com/glossary/catalyst-optimizer&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;source&lt;/a&gt;]
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;pyspark&quot;&gt;PySpark&lt;/h2&gt;

&lt;p&gt;In the Python driver program, SparkContext uses  &lt;a href=&quot;https://www.py4j.org/&quot;&gt;Py4J&lt;/a&gt;  to launch a JVM and create a JavaSparkContext. Py4J is only used on the driver for local communication between the Python and Java SparkContext objects; large data transfers are performed through a different mechanism.&lt;/p&gt;

&lt;h1 id=&quot;-read-more&quot;&gt;üëÄ Read more&lt;/h1&gt;

&lt;p&gt;Read the rest of the article ‚Ä¶&lt;/p&gt;

&lt;div style=&quot;text-align: center;margin-bottom: 1em;&quot;&gt;
  &lt;a href=&quot;https://medium.com/@glegoux/apache-spark-ecosystem-with-hadoop-apache-yarn-and-hdfs-8e64eeba68c0&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; title=&quot;Read more&quot;&gt;
    &lt;button class=&quot;btn btn-dark&quot;&gt;
      &lt;b class=&quot;black&quot;&gt;Read more&lt;/b&gt;
    &lt;/button&gt;
  &lt;/a&gt;
&lt;/div&gt;

</description>
        <pubDate>Wed, 02 Nov 2022 00:00:00 +0000</pubDate>
        <link>https://glegoux.com/blog/articles/2022/11/02/apache-spark-ecosystem-overview-with-apache-hadoop-yarn-and-hdfs.html</link>
        <guid isPermaLink="true">https://glegoux.com/blog/articles/2022/11/02/apache-spark-ecosystem-overview-with-apache-hadoop-yarn-and-hdfs.html</guid>
        
        
        <category>Data</category>
        
      </item>
    
      <item>
        <title>My tech blog on Medium</title>
        <description>&lt;p&gt;I will continue writing blog posts here, but mainly, they will be published on Medium under the user &lt;a href=&quot;https://medium.com/@glegoux&quot;&gt;@glegoux&lt;/a&gt;. The goal is always to improve the experience of readers and my experience of writing. After having re-evaluated the market of the online editors, the Medium platform is mature and becoming more and more popular, being one of the leaders among the editors of tech blogs now. It provides a full WYSIWYG user interface when editing online, with various formatting options provided as the user edits. It allows publishing blog posts (called stories) to capture large audiences and communities.&lt;/p&gt;

&lt;p&gt;With the evolution of practices and tools of online blogging these last years, I wanted to cross a threshold in my tech writer experience: be more efficient and effective in writing content by allocating less time to maintain editor tools and more time to write content. So, I needed to choose between continuing to use only this blog, starting to use only Medium, using both, or something else. I chose to use both:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The top and popular blog posts will be published on Medium in priority to gain visibility&lt;/li&gt;
  &lt;li&gt;While the other ones will remain on this blog.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;content&quot;&gt;
  &lt;div&gt;
    &lt;img class=&quot;img-fluid lazyload&quot; data-src=&quot;https://docs.google.com/drawings/d/e/2PACX-1vRwK7XcVBBYBxZhx3_nqSjUF4boYbf9BBdHP-HJYOlx2vX2Pe_scKcZTZFys9K5BEaaYmrGPN_3WziZ/pub?w=798&amp;amp;h=100&quot; alt=&quot;Migration from glegoux.com to Medium&quot; title=&quot;Migration from glegoux.com to Medium&quot; /&gt;
  &lt;/div&gt;
  &lt;figcaption&gt;
    Migration from glegoux.com to Medium
    
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;After evaluating and testing Medium, here are the pros and cons of using Medium vs. my blog:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr class=&quot;text-center&quot;&gt;
      &lt;th&gt;‚úÖ Pros&lt;/th&gt;
      &lt;th&gt;‚ùå Cons&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tr&gt;
    &lt;td style=&quot;vertical-align: top;&quot;&gt;
‚Ä¢ Medium editor is quicker and handier in updating a post with simple assets like text and images, more intuitive than YAFIYGI, and with instant updates without delay during the deployment of new content like with Jekyll used for my blog&lt;br /&gt;
‚Ä¢ Medium has advanced features of collaboration with co-writers, claps, peer comments, and followers, not all available on my blog natively and smoothly&lt;br /&gt;
‚Ä¢ Medium decorates the post with an auto-estimation of reading, no need to fill manually, and an auto-listen generation not available on my blog natively&lt;br /&gt;
‚Ä¢ Medium offers stats with custom metrics (reads, etc.) for each story more relevant than using a third party solution like Google Analytics used on my blog
    &lt;/td&gt;
    &lt;td style=&quot;vertical-align: top;&quot;&gt;
‚Ä¢ Medium has partial propriety of the written content and limits the number of readings for non-members while my blog is free and unlimited open&lt;br /&gt;
‚Ä¢ The Medium content has a pre-defined style of design. It is not highly customizable like the content on my blog&lt;br /&gt;
‚Ä¢ The Medium features remain less advanced in pushing varied content like dynamic technical diagrams and mathematics formulae, while some workarounds exist, my blog allows it
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;For all these reasons, the right choice is a consensus by keeping the best of these 2 worlds. Also, I prefer remaining independent for the long term,
and &lt;a href=&quot;https://glegoux.com&quot;&gt;https://glegoux.com&lt;/a&gt; is not only a tech blog but a hub of centralized online activities.&lt;/p&gt;

&lt;p&gt;Don‚Äôt worry, and I am going to keep maintaining this website and the open-source template behind it. To avoid all breaking changes, the past blog posts will remain accessible without breaking their web links.&lt;/p&gt;

&lt;p&gt;However, it seems time-costly to synchronize the content between Medium and this blog bi-directionally. I can import a post to Medium by copying the link manually, but exporting from Medium to markdown is long and tedious (previous native feature has been closed, and no external, mature and existing tools doing it in my knowdlege). The synchronization in case of updating a blog post from Medium becomes a nightmare to maintain, and should be done manually. In contrast, I want to use Medium editor more, which is quicker and more handy. So, as I explained, I foresee that some articles will be only on Medium and others only on this blog. If necessary, if I want to have one at both locations, instead of having a full post everywhere, I will use web links between them, with a partial post redirecting to the full post (to avoid divergences and too heavy maintenance in case of multiple post-editions).&lt;/p&gt;

&lt;p&gt;üôè Thanks for your understanding and your readings.&lt;/p&gt;

&lt;div style=&quot;height: 200px&quot;&gt;&lt;/div&gt;
</description>
        <pubDate>Tue, 01 Nov 2022 00:00:00 +0000</pubDate>
        <link>https://glegoux.com/blog/articles/2022/11/01/my-tech-blog-on-medium.html</link>
        <guid isPermaLink="true">https://glegoux.com/blog/articles/2022/11/01/my-tech-blog-on-medium.html</guid>
        
        
        <category>News</category>
        
      </item>
    
  </channel>
</rss>
