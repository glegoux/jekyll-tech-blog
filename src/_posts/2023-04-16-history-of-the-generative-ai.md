---
title: "History of the Generative AI"
description: "The rise in power of the generative AI is a revolution based on Deep Learning, it transformed the tech world into a new one."
authors: ["glegoux"]
time_reading_minutes: 9
category: "Machine Learning"
---

**Generative AI**  is the state of the art of machine learning and has excelled recently with the apparition of  **AI ChatBots with high performance**.

![](https://miro.medium.com/v2/resize:fit:700/1*UenOkL0Tn-XuP-hOho9b3Q.png)

Generative AI for all types of content

Let‚Äôs discover its history, from simple textual machine learning models specialized to  **universal**  **large language models** at a vast scale:

-   üí¨ AI ChatBots
-   üî• From NLP to Multimodal GAI ChatBots based on LLM
-   üß™LLMs Timeline: Closed-source vs. Open-source
-   üéØ From Specialized Model to Generalized ML Model
-   üìà Scaling Laws & Performance
-   üèÅ Technologic and Economic Race
-   üöÄ Go Further with Limited & Augmented LLMs

# üí¨ AI ChatBots

Building generalist  **AI chatbots**  is the most complex challenge for a technology that simulates human intelligence. It is the  **base of the artificial human assistant**. They are experiencing dazzling success with the  **release of ChatGPT**, a new step that has been overcome after Google Home and Alexa by AWS. The technical component behind these products has disrupted and improved the ecosystem considerably,  **although not perfect yet**  (perhaps it will never be).

The interest in chatBots followed the one for deep learning from 2010. Before, it was reserved for a restrained audience. Still, it exploded in  **November 2022**  with the release of  **chatGPT**  open to the general public with a ramp-up of  **100M Monthly Active Users (MAUs) after two months**, a  worldwide record (4.5x faster than TikTok) and  **1.6B MAUs now**. At the same time, machine learning and deep learning trends have continued growing in the background for ten years.

![](https://miro.medium.com/v2/resize:fit:961/1*imwYfo_SLbjeVzeZ420QhQ.png)

![](https://miro.medium.com/v2/resize:fit:853/1*bdBhXytZGBsTrI3t-zxd4A.png)

Google Trends from 2010 [source] | Similar web for chat.openai.com [[source](https://www.similarweb.com/website/chat.openai.com/#ranking)]

To have an order of magnitude, the human brain has, on average, 100 billion neurons and 100 trillion synapses. The estimated resources used for  **chatGPT+**  (paying version of chatGPT) use deep learning models based on GPT-4 with an estimated model size close to these values (digits kept private by OpenAI). But a  **human neuron/synapse**  is much more powerful than a  **deep learning neuron/synapse.** The gap is still important, above on reasoning tasks on unknown problems requiring many resources.

![](https://miro.medium.com/v2/resize:fit:382/1*Ty6-E7apO67lSr02i-6kvQ.png)

Human brain vs. Deep learning

# üî•From NLP to Multimodal GAI ChatBots based on LLM

Thanks to  **Large Language Models (LLMs)**  working with Generative AI, chatBots continue getting closer to the objective of simulating  human intelligence**.**  The  **NLP AI models**  have progressively migrated from simple parsing to c**omplex processing on the language structure**, from shallow learning to  **deep learning**, from a single-language vocabulary of words to a  **vocabulary of tokens with multi-language embeddings**, from an RNN (LSTM) to the  **Transformer with multi-head attention layers**  approach.

![](https://miro.medium.com/v2/resize:fit:700/1*4N5CPyYSVFzfEapqGM5gug.png)

NLP timeline with the Deep Learning  [[source](https://arxiv.org/pdf/2202.05924.pdf)]

Finally, by mixing other types of data (like images, audio, ‚Ä¶), NLP models became  **multi-modal generative models** where varied instructions (in input) give varied results (in output).

See the rest of the article [here](https://medium.com/@glegoux/history-of-the-generative-ai-aa1aa7c63f3c).

